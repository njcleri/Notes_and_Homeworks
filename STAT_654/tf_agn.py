# -*- coding: utf-8 -*-
"""project_comb.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15z3bNe6sZ62RvjYqwuDdzk2RbwrZqYRN
"""

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
import tensorflow_decision_forests as tfdf
from tensorflow.keras import layers
from tensorflow.keras.layers import IntegerLookup
from tensorflow.keras.layers import Normalization
from tensorflow.keras.layers import StringLookup
try:
  from wurlitzer import sys_pipes
except:
  from colabtools.googlelog import CaptureLog as sys_pipes
from sklearn.model_selection import KFold

plt.rcParams['figure.dpi'] = 300
plt.rcParams["axes.labelsize"] = 20


def encode_numerical_feature(feature, name, dataset):
    # Create a Normalization layer for our feature
    normalizer = Normalization()

    # Prepare a Dataset that only yields our feature
    feature_ds = dataset.map(lambda x, y: x[name])
    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))

    # Learn the statistics of the data
    normalizer.adapt(feature_ds)

    # Normalize the input feature
    encoded_feature = normalizer(feature)
    return encoded_feature

def encode_categorical_feature(feature, name, dataset, is_string):
    lookup_class = StringLookup if is_string else IntegerLookup
    # Create a lookup layer which will turn strings into integer indices
    lookup = lookup_class(output_mode="binary")

    # Prepare a Dataset that only yields our feature
    feature_ds = dataset.map(lambda x, y: x[name])
    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))

    # Learn set of possible string values and assign them a fixed integer index
    lookup.adapt(feature_ds)

    # Turn the string input into integer indices
    encoded_feature = lookup(feature)
    return encoded_feature

def dataframe_to_dataset(dataframe):
    dataframe = dataframe.copy()
    labels = dataframe.pop("Type_f")
    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))
    ds = ds.shuffle(buffer_size=len(dataframe))
    return ds

def split_dataset(dataset, test_ratio=0.20):
  """Splits a panda dataframe in two."""
  test_indices = np.random.rand(len(dataset)) < test_ratio
  return dataset[~test_indices], dataset[test_indices]

def plot_loss(history):
  print(history.history['loss'])
  print(history.history['val_loss'])
  plt.plot(history.history['loss'], label='Loss')
  plt.xlabel('Epoch')
  plt.ylabel('Loss')
  plt.legend()
  plt.grid(True)
  plt.title("Loss Function for Neural Network")

dataframe = pd.read_csv('chandra_xray.csv')
dataframe = dataframe.drop('Type', axis=1)
dataframe = dataframe.drop('Lx', axis=1)
dataframe = dataframe.dropna()
val_dataframe = dataframe.sample(frac=0.2, random_state=1337)
train_dataframe = dataframe.drop(val_dataframe.index)
print("Using %d samples for training and %d for validation")

train_ds = dataframe_to_dataset(train_dataframe)
val_ds = dataframe_to_dataset(val_dataframe)

for x, y in train_ds.take(1):
    print("Input:", x)
    print("Target:", y)

train_ds = train_ds.batch(32)
val_ds = val_ds.batch(32)

# Numerical features
zadopt = keras.Input(shape=(1,), name="zadopt")
FExp = keras.Input(shape=(1,), name="FExp")
SExp = keras.Input(shape=(1,), name="SExp")
HExp = keras.Input(shape=(1,), name="HExp")
BRat = keras.Input(shape=(1,), name="BRat")
PInd = keras.Input(shape=(1,), name="PInd")
FFlux = keras.Input(shape=(1,), name="FFlux")
SFlux = keras.Input(shape=(1,), name="SFlux")
HFlux = keras.Input(shape=(1,), name="HFlux")
log_Lx = keras.Input(shape=(1,), name="log_Lx")

all_inputs = [
    zadopt,
    FExp,
    SExp,
    HExp,
    BRat,
    PInd,
    FFlux,
    SFlux,
    HFlux,
    log_Lx,
]

# Numerical features
zadopt_enc = encode_numerical_feature(zadopt, "zadopt", train_ds)
FExp_enc = encode_numerical_feature(FExp, "FExp", train_ds)
SExp_enc = encode_numerical_feature(SExp, "SExp", train_ds)
HExp_enc = encode_numerical_feature(HExp, "HExp", train_ds)
BRat_enc = encode_numerical_feature(BRat, "BRat", train_ds)
PInd_enc = encode_numerical_feature(PInd, "PInd", train_ds)
FFlux_enc = encode_numerical_feature(FFlux, "FFlux", train_ds)
SFlux_enc = encode_numerical_feature(SFlux, "SFlux", train_ds)
HFlux_enc = encode_numerical_feature(HFlux, "HFlux", train_ds)
log_Lx_enc = encode_numerical_feature(log_Lx, "log_Lx", train_ds)

all_features = layers.concatenate(
    [
        zadopt_enc,
        FExp_enc,
        SExp_enc,
        HExp_enc,
        BRat_enc,
        PInd_enc,
        FFlux_enc,
        SFlux_enc,
        HFlux_enc,
        log_Lx_enc,
    ]
)
x = layers.Dense(32, activation="relu")(all_features)
x = layers.Dropout(0.5)(x)
output = layers.Dense(1, activation="sigmoid")(x)
model = keras.Model(all_inputs, output)
model.compile("adam", "binary_crossentropy", metrics=["accuracy"])

# `rankdir='LR'` is to make the graph horizontal.
keras.utils.plot_model(model, show_shapes=True, rankdir="LR")

model.fit(train_ds, epochs=50, validation_data=val_ds)
model.summary(show_trainable=True)

history = model.fit(
    train_features,
    train_labels,
    epochs=100,
    verbose = 0,
     # Calculate validation results on 20% of the training data.
    validation_split = 0.2)

plot_loss(history)

plt.figure(figsize=(12, 4))

plt.subplot(1, 2, 1)
plt.plot(history.history['val_accuracy'])
plt.xlabel("Epoch")
plt.ylabel("Validation Accuracy")

plt.subplot(1, 2, 2)
plt.plot(history.history['val_loss'])
plt.xlabel("Epoch")
plt.ylabel("Validation Loss")

plt.show()

sns.pairplot(train_work[['zadopt', 'FExp', 'SExp', 'HExp', 'BRat', 'PInd', 
                         'FFlux', 'SFlux', 'HFlux', 'log_Lx', 'Type_f']], 
             diag_kind='kde')

### DECISION FORESTS

#read in the data
#unnecessary if running in one .py with nn
# dataset_df = pd.read_csv("chandra_xray.csv")

#drop the two redunant columns (replaced with log_lx and Type_f)
# dataset_df = dataset_df.drop(['Lx', 'Type'], axis = 1)

#split the sample into train and test subsamples
train_ds_pd, test_ds_pd = split_dataset(dataset_df)
print("{} examples in training, {} examples for testing.".format(
    len(train_ds_pd), len(test_ds_pd)))

label = "Type_f"
classes = dataset_df[label].unique().tolist()
print(f"Label classes: {classes}")

dataset_df[label] = dataset_df[label].map(classes.index)

train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_ds_pd, label=label)
test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test_ds_pd, label=label)

### Testing RF VS GBDF models using k-fold validation
# Random Forest Model with default parameters

kf = KFold(n_splits=10, shuffle=True)
kf.get_n_splits(dataset_df)
print(kf)
model_1_accuracy = 0
for train_index, test_index in kf.split(dataset_df):
  X_train, X_test = dataset_df.iloc[train_index], dataset_df.iloc[test_index]
  train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(X_train, label=label)
  test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(X_test, label=label)
  model_1 = tfdf.keras.RandomForestModel()
  model_1.compile(metrics = ["accuracy"])
  model_1.fit(x=train_ds, validation_data=test_ds)
  model_1.evaluate(test_ds, return_dict=True)
  model_1_accuracy += (model_1.make_inspector().evaluation()[1])

model_1_accuracy = model_1_accuracy/10

#create the random forest plot
tfdf.model_plotter.plot_model_in_colab(model_1, tree_idx=0, max_depth=4)

#plot log(loss) and accuracy for random forest
logs = model_1.make_inspector().training_logs()

plt.figure(figsize=(12, 4))

plt.subplot(1, 2, 1)
plt.plot([log.num_trees for log in logs], 
         [log.evaluation.accuracy for log in logs])
plt.xlabel("Number of trees")
plt.ylabel("Accuracy")

plt.subplot(1, 2, 2)
plt.plot([log.num_trees for log in logs], 
         [log.evaluation.loss for log in logs])
plt.xlabel("Number of trees")
plt.ylabel("Log(loss)")

plt.suptitle("Random Forest")
plt.show()

### GBDF Models

#GBDF with Default Parameters
kf = KFold(n_splits=10, shuffle=True)
kf.get_n_splits(dataset_df)
print(kf)
model_2_accuracy = 0
for train_index, test_index in kf.split(dataset_df):
  X_train, X_test = dataset_df.iloc[train_index], dataset_df.iloc[test_index]
  train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(X_train, label=label)
  test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(X_test, label=label)
  model_2 = tfdf.keras.GradientBoostedTreesModel()
  model_2.compile(metrics = ["accuracy"])
  model_2.fit(x=train_ds, validation_data=test_ds)
  model_2.evaluate(test_ds, return_dict=True)
  model_2_accuracy += (model_2.make_inspector().evaluation()[1])

model_2_accuracy = model_2_accuracy/10

#GBDF with hyperparameter template 'better_default'
kf = KFold(n_splits=10, shuffle=True)
kf.get_n_splits(dataset_df)
print(kf)
model_3_accuracy = 0
for train_index, test_index in kf.split(dataset_df):
  X_train, X_test = dataset_df.iloc[train_index], dataset_df.iloc[test_index]
  train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(X_train, label=label)
  test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(X_test, label=label)
  model_3 = tfdf.keras.GradientBoostedTreesModel(hyperparameter_template='better_default')
  model_3.compile(metrics = ["accuracy"])
  model_3.fit(x=train_ds, validation_data=test_ds)
  model_3.evaluate(test_ds, return_dict=True)
  model_3_accuracy += (model_3.make_inspector().evaluation()[1])

model_3_accuracy = model_3_accuracy/10


#GBDF with hyperparameter template 'benchmark_rank1'
kf = KFold(n_splits=10, shuffle=True)
kf.get_n_splits(dataset_df)
print(kf)
model_4_accuracy = 0
for train_index, test_index in kf.split(dataset_df):
  X_train, X_test = dataset_df.iloc[train_index], dataset_df.iloc[test_index]
  train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(X_train, label=label)
  test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(X_test, label=label)
  model_4 = tfdf.keras.GradientBoostedTreesModel(hyperparameter_template="benchmark_rank1")
  model_4.compile(metrics = ["accuracy"])
  model_4.fit(x=train_ds, validation_data=test_ds)
  model_4.evaluate(test_ds, return_dict=False)
  model_4_accuracy += (model_4.make_inspector().evaluation()[1])

model_4_accuracy = model_4_accuracy/10

#print results from k-fold validation
print("Random Forest: ", model_1_accuracy)
print("Default: ", model_2_accuracy)
print("Best First Global: ", model_3_accuracy)
print("Sparse Oblique: ", model_4_accuracy)

#Plot GBDF with default parameters
logs = model_2.make_inspector().training_logs()

plt.figure(figsize=(12, 4))

plt.subplot(1, 2, 1)
plt.plot([log.num_trees for log in logs], 
         [log.evaluation.accuracy for log in logs])
plt.xlabel("Number of trees")
plt.ylabel("Accuracy")

plt.subplot(1, 2, 2)
plt.plot([log.num_trees for log in logs], [log.evaluation.loss for log in logs])
plt.xlabel("Number of trees")
plt.ylabel("Log(loss)")

plt.suptitle('Gradient Boosted Decision Forest')
plt.show()

# Varying number of trees in default GBDF model 
# from 5-25 because it appears to be overfitting

inspector = model_2.make_inspector()
print(inspector.num_trees())

kf = KFold(n_splits=10, shuffle=True)
kf.get_n_splits(dataset_df)
print(kf)
model_5_accuracy = 0
for train_index, test_index in kf.split(dataset_df):
  X_train, X_test = dataset_df.iloc[train_index], dataset_df.iloc[test_index]
  train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(X_train, label=label)
  test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(X_test, label=label)
  model_5 = tfdf.keras.GradientBoostedTreesModel(num_trees = 5)
  model_5.compile(metrics = ["accuracy"])
  model_5.fit(x=train_ds, validation_data=test_ds)
  model_5.evaluate(test_ds, return_dict=True)
  model_5_accuracy += (model_5.make_inspector().evaluation()[1])

model_5_accuracy = model_5_accuracy/10

kf = KFold(n_splits=10, shuffle=True)
kf.get_n_splits(dataset_df)
print(kf)
model_8_accuracy = 0
for train_index, test_index in kf.split(dataset_df):
  X_train, X_test = dataset_df.iloc[train_index], dataset_df.iloc[test_index]
  train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(X_train, label=label)
  test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(X_test, label=label)
  model_6 = tfdf.keras.GradientBoostedTreesModel(num_trees = 10, verbose = 0)
  model_6.compile(metrics = ["accuracy"])
  model_6.fit(x=train_ds, validation_data=test_ds)
  model_6.evaluate(test_ds, return_dict=False)
  model_6_accuracy += (model_6.make_inspector().evaluation()[1])

model_6_accuracy = model_6_accuracy/10

kf = KFold(n_splits=10, shuffle=True)
kf.get_n_splits(dataset_df)
print(kf)
model_7_accuracy = 0
for train_index, test_index in kf.split(dataset_df):
  X_train, X_test = dataset_df.iloc[train_index], dataset_df.iloc[test_index]
  train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(X_train, label=label)
  test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(X_test, label=label)
  model_7 = tfdf.keras.GradientBoostedTreesModel(num_trees = 15)
  model_7.compile(metrics = ["accuracy"])
  model_7.fit(x=train_ds, validation_data=test_ds)
  model_7.evaluate(test_ds, return_dict=True)
  model_7_accuracy += (model_7.make_inspector().evaluation()[1])

model_7_accuracy = model_7_accuracy/10

kf = KFold(n_splits=10, shuffle=True)
kf.get_n_splits(dataset_df)
print(kf)
model_8_accuracy = 0
for train_index, test_index in kf.split(dataset_df):
  X_train, X_test = dataset_df.iloc[train_index], dataset_df.iloc[test_index]
  train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(X_train, label=label)
  test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(X_test, label=label)
  model_8 = tfdf.keras.GradientBoostedTreesModel(num_trees = 20)
  model_8.compile(metrics = ["accuracy"])
  model_8.fit(x=train_ds, validation_data=test_ds)
  model_8.evaluate(test_ds, return_dict=True)
  model_8_accuracy += (model_8.make_inspector().evaluation()[1])

model_8_accuracy = model_8_accuracy/10

kf = KFold(n_splits=10, shuffle=True)
kf.get_n_splits(dataset_df)
print(kf)
model_9_accuracy = 0
for train_index, test_index in kf.split(dataset_df):
  X_train, X_test = dataset_df.iloc[train_index], dataset_df.iloc[test_index]
  train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(X_train, label=label)
  test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(X_test, label=label)
  model_9 = tfdf.keras.GradientBoostedTreesModel(num_trees = 25)
  model_9.compile(metrics = ["accuracy"])
  model_9.fit(x=train_ds, validation_data=test_ds)
  model_9.evaluate(test_ds, return_dict=True)
  model_9_accuracy += (model_9.make_inspector().evaluation()[1])

model_9_accuracy = model_9_accuracy/10

print("GBDF 300: ", model_2_accuracy)
print("GBDF 5: ", model_5_accuracy)
print("GBDF 10: ", model_6_accuracy)
print("GBDF 15: ", model_7_accuracy)
print("GBDF 20: ", model_8_accuracy)
print("GBDF 25: ", model_9_accuracy)

num_trees = [model_5.make_inspector().num_trees(),
             model_6.make_inspector().num_trees(),
             model_7.make_inspector().num_trees(),
             model_8.make_inspector().num_trees(),
             model_9.make_inspector().num_trees(),
             model_2.make_inspector().num_trees()]
accuracies = [model_5_accuracy, model_6_accuracy, model_7_accuracy, 
              model_8_accuracy, model_9_accuracy, model_2_accuracy]

plt.scatter(num_trees, accuracies)
plt.xlabel("Number of Trees")
plt.ylabel("Average Validation Accuracy")
plt.show()

logs = model_8.make_inspector().training_logs()

plt.figure(figsize=(12, 4))

plt.subplot(1, 2, 1)
plt.plot([log.num_trees for log in logs], 
         [log.evaluation.accuracy for log in logs])
plt.xlabel("Number of trees")
plt.ylabel("Accuracy")

plt.subplot(1, 2, 2)
plt.plot([log.num_trees for log in logs], [log.evaluation.loss for log in logs])
plt.xlabel("Number of trees")
plt.ylabel("Log(loss)")

plt.suptitle('Gradient Boosted Decision Forest')
plt.show()

sum_score = model_8.make_inspector().variable_importances()['SUM_SCORE']
scores = [0]*len(sum_score)
feature_names = [0]*len(sum_score)
for i in range(len(sum_score)):
  scores[i] = sum_score[i][1]
  feature_names[i] = sum_score[i][0][0]

scores = np.array(scores)
scores = scores/scores[0]
plt.bar(feature_names, scores)
plt.xlabel('Predictor')
plt.ylabel('Relative Importance')
plt.show()